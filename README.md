# Awesome-CV-Attention

If you have any problems, suggestions or improvements, please submit the issue or PR.

## Contents
* [Misc](#misc)
* [Datasets](#datasets)
* [Papers](#papers)
* [Leaderboard](#leaderboard)

## Misc



### Challenge


### Code


### Technical blog
- 深度学习注意力与记忆机制[[Link](https://mp.weixin.qq.com/s/FlA1YrR0sLQGJoJZnSXpRw)]
- 涨点神器GSA：全局自注意力网络，打造更强注意力模型[[Link](https://mp.weixin.qq.com/s/7L4R3kOgK-xS2cXS0u5zww)]
- 一文看懂CV中的注意力机制[[Link](https://mp.weixin.qq.com/s/gDJJDxNnU4lNFOy0lmrPGQ)]

## Datasets

Please refer to [this page](src/Datasets.md).

## Papers

Considering the increasing number of papers in this field, we roughly summarize some articles and put them into the following categories (they are still listed in this document):


### arXiv papers
Note that all unpublished arXiv papers are not included in [the leaderboard of performance](#performance).

- Rotate to Attend: Convolutional Triplet Attention Module[[paper](https://arxiv.org/abs/2010.03045)][[code](https://github.com/LandskapeAI/triplet-attention)]  
- Neural encoding with visual attention[[paper](https://arxiv.org/abs/2010.00516)]  
Research on this paper [[Link](https://mp.weixin.qq.com/s/zBr_x6QKbGxJzQp3YzrmnQ)]
- Deep High-Resolution Representation Learning for Visual Recognition[[paper](https://arxiv.org/abs/1908.07919)][[code](https://github.com/HRNet)][[video](https://www.bilibili.com/video/BV1WJ41197dh?t=508)]   
Research on this paper [[Link](https://mp.weixin.qq.com/s?__biz=MzU2NDExMzE5Nw==&mid=2247485243&idx=2&sn=4cf73ac84bdf064b649f6bf0aa8b3930&chksm=fc4ebd79cb39346f19a70eb07e35c3d61e43487ecd83d397f31e464f5584f6be9b1b0ccfb09e&mpshare=1&scene=1&srcid=1010LkNbbYg5EzUcwB7gHcjE&sharer_sharetime=1602303490397&sharer_shareid=fd8c7684b39b2eac07b5e0c63bf1346a&key=14893ff72db1d5ee0088db18c310b8b6d459213d96a45f2a2c3af4afcb702a473a9d643b8f9f259c0e87f83e0199fcb18a7a950b720b506b50d953252d989e40fa5d599ec976c1d960211439c1308af60e0a76154d9d88b26710883344a9b109679d4f6c8e3fb6c65081a34e4e1f609c3e72c9080b4bfa1b99f9003fa3bd7e4c&ascene=1&uin=Mjg1Mzg0ODMzMA%3D%3D&devicetype=Windows+10+x64&version=6300002f&lang=zh_CN&exportkey=ASBpO%2BjtjEg7X6MctgYfDKI%3D&pass_ticket=Cz67wUTL3RpVi0NHLVPCJOM8DtIHGFNJZqgE5Tk%2FDHEDHwgbRWtMAfGco6cfR%2BOZ&wx_header=0)]
- Attentional Feature Fusion[[paper](https://arxiv.org/abs/2009.14082)][[paper](https://arxiv.org/abs/2009.14082)][[code](https://github.com/YimianDai/open-aff)]   
Research on this paper [[Link](https://mp.weixin.qq.com/s?__biz=MzUxNjcxMjQxNg==&mid=2247509314&idx=2&sn=962a197a40a441bdb5a35d7993a4f521&chksm=f9a1d7cdced65edb847f09f2fd0dbe17e9d27de840afadc69a9cb20bbc83e1b439617a49aa34&mpshare=1&scene=1&srcid=10108dxJMkf8tKkzf9Q4gmbz&sharer_sharetime=1602309038539&sharer_shareid=fd8c7684b39b2eac07b5e0c63bf1346a&key=b06d693918fd14f437767792fe308e539c57ddd684d914fdf5b98a4933279ac37d1c21175610180011d4225faed5bb8ba53e1afb5b73cd56efde3b132426da44470266acfb15fc89296b18817f23e22f34da9e7bf3e357aeca9830bd100e24ba069eadb38aadb609f737e76ae8dadf0e48a9a409ac26566e3aaa3ea15595c80a&ascene=1&uin=Mjg1Mzg0ODMzMA%3D%3D&devicetype=Windows+10+x64&version=6300002f&lang=zh_CN&exportkey=AXTxIop%2BTmhgeVHk%2BWrTNkI%3D&pass_ticket=Cz67wUTL3RpVi0NHLVPCJOM8DtIHGFNJZqgE5Tk%2FDHEDHwgbRWtMAfGco6cfR%2BOZ&wx_header=0)]
- Rethinking Attention with Performers[[paper](https://arxiv.org/abs/2009.14794)][[code](https://github.com/google-research/google-research/tree/master/performer/fast_self_attention?utm_source=catalyzex.com)]  
Research on this paper [[Link](https://mp.weixin.qq.com/s/WkB8Oy1-SrQPQcYUe6vrgQ)]

<details>
<summary>Earlier ArXiv Papers</summary>

</details>


### 2020
- DCANet: Learning Connected Attentions for Convolutional Neural Networks (ECCV-2020)[[paper](https://arxiv.org/abs/2007.05099)]  
Research on this paper [[Link](https://mp.weixin.qq.com/s/xJgL3t63ipfv2JYsOZpeYg)]
- Squeeze-and-Attention Networks for Semantic Segmentation (CVPR-2020)[[paper](https://arxiv.org/abs/1909.03402)]
- Gated Channel Transformation for Visual Recognition (CVPR-2020)[[paper](https://arxiv.org/abs/1909.11519)][[code](https://github.com/z-x-yang/GCT)]  
Research on this paper [[Link](https://mp.weixin.qq.com/s/0CA-flSdUV3lPjzRGzvOvA)]
- ResNeSt: Split-Attention Networks (CVPR)[[paper](https://hangzhang.org/files/resnest.pdf)][[code](https://github.com/zhanghang1989/ResNeSt)]   
Research on this paper [[Link](https://mp.weixin.qq.com/s/65ueZDuZ-b3_VnGdQbrk_g)]
- <a name="D-ConvNet"></a> **[HAttMatting]** Attention-Guided Hierarchical Structure Aggregation for Image Matting (CVPR)[[paper](https://ieeexplore.ieee.org/document/9156481)][[code](https://github.com/implus/SKNet)]  
Research on this paper [[Link](https://mp.weixin.qq.com/s/bXyz0cEfVfL_VrFFV2NzTQ)]
- Weight Excitation: Built-in Attention Mechanisms in Convolutional Neural Networks (ECCV-2020)[[paper](https://ieeexplore.ieee.org/document/9156481)]  
Research on this paper [[Link](https://mp.weixin.qq.com/s/ilx839gI2Av06dAlOXiR5g)]

### 2019
- Deep High-Resolution Representation Learning for Visual Recognition(CVPR-2019)[[paper](https://arxiv.org/abs/1908.07919)][[code](https://github.com/HRNet)]    
Research on this paper [[Link](https://mp.weixin.qq.com/s/2bBp_mSl4qM5lQMfpkzDnQ)]
- Selective Kernel Networks (CVPR-2019)[[paper](https://arxiv.org/abs/1903.06586)][[code](https://github.com/implus/SKNet)]  
Research on this paper [[Link](https://mp.weixin.qq.com/s/oxkoh6VnXV2CX3-BmXbZOw)]
### 2018
- Non-local Neural Networks (CVPR 2018)[[paper](https://arxiv.org/abs/1711.07971)][[code](https://github.com/facebookresearch/video-nonlocal-net)]    
Research on this paper [[Link](https://zhuanlan.zhihu.com/p/102984842)]
- Dual Attention Network for Scene Segmentation (CVPR-2018)[[paper](https://arxiv.org/abs/1809.02983)][[code](https://github.com/junfu1115/DANet)]  
Research on this paper [[Link](https://zhuanlan.zhihu.com/p/48056789)]
- Squeeze-and-Excitation Networks(CVPR-2018) [[paper](https://arxiv.org/abs/1709.01507)][[code](https://github.com/hujie-frank/SENet)] Pytorch[[code](https://github.com/moskomule/senet.pytorch)]  
Research on this paper [[Link](https://mp.weixin.qq.com/s/a-dswrPWBrk9YL8KEhTlsg)]
- <a name="SANet"></a> **[CBAM]** Convolutional Block Attention Module (ECCV)[[paper](https://openaccess.thecvf.com/content_ECCV_2018/papers/Sanghyun_Woo_Convolutional_Block_Attention_ECCV_2018_paper.pdf)]  
Research on this paper [[Link](https://zhuanlan.zhihu.com/p/65529934)]

### 2017
- <a name="SANet"></a> **[CTFM]** SCA-CNN: Spatial and Channel-wise Attention in Convolutional Networks for Image Captioning (CVPR)[[paper](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chen_SCA-CNN_Spatial_and_CVPR_2017_paper.pdf)]

## Leaderboard
The section is being continually updated. Note that some values have superscript, which indicates their source. 

